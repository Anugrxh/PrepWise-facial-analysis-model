import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from rest_framework.decorators import api_view, parser_classes
from rest_framework.parsers import MultiPartParser, FileUploadParser
from rest_framework.response import Response
from rest_framework import status
from django.conf import settings
import os
import tempfile
import threading
from concurrent.futures import ThreadPoolExecutor
import time

# Global model instance for optimization
_model = None
_model_lock = threading.Lock()

def get_emotion_model():
    """Singleton pattern for model loading to avoid reloading"""
    global _model
    if _model is None:
        with _model_lock:
            if _model is None:
                model_path = os.path.join(settings.BASE_DIR, 'emotion_detction_model.h5')
                _model = load_model(model_path)
                # Warm up the model
                dummy_input = np.zeros((1, 48, 48, 1))
                _model.predict(dummy_input)
    return _model

# Emotion labels mapping
EMOTION_LABELS = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']

def preprocess_face(face_roi):
    """Optimized face preprocessing"""
    face_roi = cv2.resize(face_roi, (48, 48))
    face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
    face_roi = face_roi.astype('float32') / 255.0
    face_roi = np.expand_dims(face_roi, axis=-1)
    face_roi = np.expand_dims(face_roi, axis=0)
    return face_roi

def analyze_frame_batch(frames, face_cascade, model):
    """Process multiple frames in batch for better performance"""
    emotions_data = []
    
    for frame in frames:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        
        if len(faces) > 0:
            # Take the largest face
            face = max(faces, key=lambda x: x[2] * x[3])
            x, y, w, h = face
            face_roi = frame[y:y+h, x:x+w]
            
            # Preprocess and predict
            processed_face = preprocess_face(face_roi)
            emotion_pred = model.predict(processed_face, verbose=0)[0]
            
            # Convert to emotion dictionary
            emotion_dict = {EMOTION_LABELS[i]: float(emotion_pred[i] * 100) for i in range(len(EMOTION_LABELS))}
            emotions_data.append(emotion_dict)
    
    return emotions_data

def generate_interview_feedback(avg_emotions, confidence, eye_contact, speech_clarity, overall_score):
    """Generate comprehensive interview-specific feedback based on facial analysis"""
    
    # Identify dominant emotions
    dominant_emotion = max(avg_emotions, key=avg_emotions.get)
    dominant_score = avg_emotions[dominant_emotion]
    
    # Calculate interview readiness factors
    positive_emotions = avg_emotions.get("happy", 0) + avg_emotions.get("surprise", 0)
    negative_emotions = avg_emotions.get("fear", 0) + avg_emotions.get("sad", 0) + avg_emotions.get("angry", 0)
    professional_composure = avg_emotions.get("neutral", 0)
    
    # Interview-specific emotional stability
    emotion_values = list(avg_emotions.values())
    emotional_control = 100 - (np.std(emotion_values) * 1.5)
    
    feedback_parts = []
    
    # Overall Interview Assessment
    if overall_score >= 85:
        feedback_parts.append("ðŸŽ¯ EXCELLENT CANDIDATE: Demonstrates strong interview presence with professional demeanor and confident communication. Highly likely to make a positive impression on interviewers.")
    elif overall_score >= 75:
        feedback_parts.append("âœ… STRONG CANDIDATE: Shows good interview skills with solid emotional control and professional presentation. Minor refinements could enhance performance.")
    elif overall_score >= 65:
        feedback_parts.append("ðŸ“Š COMPETENT CANDIDATE: Displays adequate interview skills with room for improvement in confidence and emotional expression.")
    elif overall_score >= 50:
        feedback_parts.append("âš ï¸ DEVELOPING CANDIDATE: Shows potential but needs significant improvement in interview presence and emotional management.")
    else:
        feedback_parts.append("ðŸ”„ NEEDS PREPARATION: Requires substantial interview coaching and practice to develop professional presence.")
    
    # Professional Demeanor Analysis
    if professional_composure >= 40 and professional_composure <= 65:
        feedback_parts.append(f"ðŸ‘” Professional Demeanor: Excellent balance of professionalism ({professional_composure:.1f}% neutral) with appropriate emotional expression. Shows maturity and composure expected in professional settings.")
    elif professional_composure > 65:
        feedback_parts.append(f"ðŸ‘” Professional Demeanor: Very composed ({professional_composure:.1f}% neutral) but may appear too reserved. Consider showing more enthusiasm about the role and company to demonstrate genuine interest.")
    else:
        feedback_parts.append(f"ðŸ‘” Professional Demeanor: Could benefit from more professional composure ({professional_composure:.1f}% neutral). Practice maintaining calm, confident demeanor even when discussing challenging topics.")
    
    # Emotional Intelligence Assessment
    if positive_emotions >= 25 and negative_emotions <= 20:
        feedback_parts.append(f"ðŸ§  Emotional Intelligence: Strong emotional awareness with {positive_emotions:.1f}% positive emotions and well-controlled stress responses. Demonstrates resilience and optimism valued by employers.")
    elif negative_emotions > 30:
        feedback_parts.append(f"ðŸ§  Emotional Intelligence: High stress indicators detected ({negative_emotions:.1f}% negative emotions). Practice relaxation techniques and mock interviews to build confidence and reduce anxiety.")
    else:
        feedback_parts.append(f"ðŸ§  Emotional Intelligence: Moderate emotional expression. Consider showing more enthusiasm and passion for the role while maintaining professionalism.")
    
    # Confidence & Leadership Presence
    if confidence >= 80:
        feedback_parts.append(f"ðŸ’¼ Leadership Presence: Exceptional confidence ({confidence}%). Projects strong leadership potential and decision-making capability. Likely to inspire confidence in hiring managers.")
    elif confidence >= 65:
        feedback_parts.append(f"ðŸ’¼ Leadership Presence: Good confidence level ({confidence}%). Shows potential for leadership roles with minor improvements in assertiveness and self-assurance.")
    elif confidence >= 50:
        feedback_parts.append(f"ðŸ’¼ Leadership Presence: Moderate confidence ({confidence}%). Focus on highlighting achievements and practicing confident body language to project stronger executive presence.")
    else:
        feedback_parts.append(f"ðŸ’¼ Leadership Presence: Building confidence ({confidence}%). Work on power posing, preparation, and positive self-talk to project stronger professional presence.")
    
    # Communication & Engagement
    if eye_contact >= 75:
        feedback_parts.append(f"ðŸ‘ï¸ Interviewer Engagement: Excellent eye contact ({eye_contact}%). Demonstrates strong interpersonal skills and genuine interest in the conversation. Creates positive rapport with interviewers.")
    elif eye_contact >= 60:
        feedback_parts.append(f"ðŸ‘ï¸ Interviewer Engagement: Good engagement level ({eye_contact}%). Maintain consistent eye contact throughout the interview, especially when discussing key achievements and asking questions.")
    elif eye_contact >= 45:
        feedback_parts.append(f"ðŸ‘ï¸ Interviewer Engagement: Moderate engagement ({eye_contact}%). Practice maintaining eye contact for 3-5 seconds at a time. This shows confidence and helps build trust with interviewers.")
    else:
        feedback_parts.append(f"ðŸ‘ï¸ Interviewer Engagement: Needs improvement ({eye_contact}%). Poor eye contact can signal lack of confidence or disinterest. Practice looking directly at interviewers when speaking and listening.")
    
    # Verbal Communication Assessment
    if speech_clarity >= 80:
        feedback_parts.append(f"ðŸ—£ï¸ Communication Skills: Excellent articulation ({speech_clarity}%). Clear, professional communication that effectively conveys ideas and demonstrates strong verbal skills.")
    elif speech_clarity >= 65:
        feedback_parts.append(f"ðŸ—£ï¸ Communication Skills: Good communication ({speech_clarity}%). Minor improvements in pace and clarity could enhance message delivery and professional impact.")
    elif speech_clarity >= 50:
        feedback_parts.append(f"ðŸ—£ï¸ Communication Skills: Adequate clarity ({speech_clarity}%). Practice speaking slowly, using pauses effectively, and ensuring clear pronunciation of key points.")
    else:
        feedback_parts.append(f"ðŸ—£ï¸ Communication Skills: Needs attention ({speech_clarity}%). Focus on articulation exercises, recording practice sessions, and speaking at appropriate pace for interview settings.")
    
    # Stress Management & Adaptability
    if emotional_control >= 70:
        feedback_parts.append("ðŸŽ¯ Stress Management: Excellent emotional regulation. Shows ability to handle pressure and unexpected questions with composure - a key trait for demanding roles.")
    elif emotional_control >= 50:
        feedback_parts.append("ðŸŽ¯ Stress Management: Good emotional stability with minor fluctuations. Practice breathing techniques and mock interviews to improve consistency under pressure.")
    else:
        feedback_parts.append("ðŸŽ¯ Stress Management: High emotional variability detected. Work on stress management techniques and practice difficult interview scenarios to build resilience.")
    
    # Interview-Specific Recommendations
    recommendations = []
    
    if confidence < 70:
        recommendations.append("Practice the STAR method for behavioral questions to boost confidence")
        recommendations.append("Research the company thoroughly to increase comfort level")
    
    if eye_contact < 65:
        recommendations.append("Practice mock interviews with friends or record yourself")
        recommendations.append("Focus on the interviewer's eyebrows if direct eye contact feels uncomfortable")
    
    if negative_emotions > 25:
        recommendations.append("Arrive 10-15 minutes early to settle nerves")
        recommendations.append("Practice deep breathing exercises before the interview")
        recommendations.append("Prepare 3-5 thoughtful questions about the role to shift focus outward")
    
    if professional_composure < 35:
        recommendations.append("Practice professional small talk and appropriate interview attire")
        recommendations.append("Work on maintaining calm, measured responses even to challenging questions")
    
    if speech_clarity < 70:
        recommendations.append("Practice common interview questions out loud daily")
        recommendations.append("Record yourself answering questions and review for clarity")
    
    if positive_emotions < 15:
        recommendations.append("Prepare specific examples that showcase your passion for the field")
        recommendations.append("Practice expressing genuine enthusiasm about the company and role")
    
    if overall_score < 65:
        recommendations.append("Schedule mock interviews with career counselors or mentors")
        recommendations.append("Join professional networking groups to practice conversational skills")
    
    # Final Assessment
    if overall_score >= 75:
        feedback_parts.append("ðŸŒŸ INTERVIEW READINESS: Strong candidate profile. Focus on company-specific preparation and showcasing relevant achievements.")
    elif overall_score >= 60:
        feedback_parts.append("ðŸ“ˆ INTERVIEW READINESS: Good foundation with targeted improvements needed. Practice specific scenarios and work on identified weak areas.")
    else:
        feedback_parts.append("ðŸŽ“ INTERVIEW READINESS: Requires focused preparation. Consider professional interview coaching and extensive mock interview practice.")
    
    if recommendations:
        feedback_parts.append("ðŸ’¡ PRIORITY ACTIONS: " + " | ".join(recommendations))
    
    return " ".join(feedback_parts)

def calculate_metrics(emotions_list):
    """Calculate aggregated metrics from emotion data"""
    if not emotions_list:
        return {
            "confidence": 0,
            "emotions": {label: 0 for label in EMOTION_LABELS},
            "eyeContact": 0,
            "speechClarity": 0,
            "overallScore": 0,
            "feedback": "âŒ INTERVIEW ANALYSIS FAILED: No face detected in the video. For accurate interview assessment: Ensure proper lighting (face the light source), maintain direct eye contact with camera, keep face clearly visible throughout recording, use stable camera position, and ensure good video quality. Consider retaking the interview video with better setup."
        }
    
    # Average emotions across all frames
    avg_emotions = {label: 0 for label in EMOTION_LABELS}
    for emotions in emotions_list:
        for label in EMOTION_LABELS:
            avg_emotions[label] += emotions.get(label, 0)
    
    for label in avg_emotions:
        avg_emotions[label] = round(avg_emotions[label] / len(emotions_list), 1)
    
    # Calculate confidence based on the highest emotion score and consistency
    max_emotion_score = max(avg_emotions.values())
    emotion_consistency = 100 - (np.std(list(avg_emotions.values())) * 2)
    confidence = min(int((max_emotion_score * 0.7 + emotion_consistency * 0.3) * 1.1), 100)
    
    # Simulate eye contact and speech clarity with more realistic calculations
    # Eye contact correlates with confidence and neutral/happy emotions
    eye_contact_base = (avg_emotions.get("neutral", 0) + avg_emotions.get("happy", 0)) * 0.4
    eye_contact = min(90, int(eye_contact_base + confidence * 0.3 + np.random.randint(-8, 12)))
    
    # Speech clarity correlates with confidence and low fear/anxiety
    speech_clarity_base = confidence * 0.6 + (100 - avg_emotions.get("fear", 0)) * 0.3
    speech_clarity = min(95, int(speech_clarity_base + np.random.randint(-5, 10)))
    
    # Calculate overall score with weighted importance
    overall_score = int((confidence * 0.4 + eye_contact * 0.3 + speech_clarity * 0.3))
    
    # Generate comprehensive interview feedback
    detailed_feedback = generate_interview_feedback(avg_emotions, confidence, eye_contact, speech_clarity, overall_score)
    
    return {
        "confidence": confidence,
        "emotions": avg_emotions,
        "eyeContact": eye_contact,
        "speechClarity": speech_clarity,
        "overallScore": overall_score,
        "feedback": detailed_feedback
    }

@api_view(['POST'])
@parser_classes([MultiPartParser, FileUploadParser])
def facial_analysis(request):
    """Optimized facial emotion analysis endpoint"""
    try:
        if 'video' not in request.FILES:
            return Response(
                {"error": "No video file provided"}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        video_file = request.FILES['video']
        
        # Save video to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
            for chunk in video_file.chunks():
                temp_file.write(chunk)
            temp_video_path = temp_file.name
        
        try:
            # Load models
            model = get_emotion_model()
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            
            # Open video
            cap = cv2.VideoCapture(temp_video_path)
            
            if not cap.isOpened():
                return Response(
                    {"error": "Could not open video file"}, 
                    status=status.HTTP_400_BAD_REQUEST
                )
            
            # Get video properties for optimization
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # Sample frames for faster processing (every 5th frame)
            frame_skip = max(1, int(fps / 6))  # Process ~6 frames per second
            frames_to_process = []
            frame_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                if frame_count % frame_skip == 0:
                    frames_to_process.append(frame)
                    
                    # Process in batches of 30 frames for memory efficiency
                    if len(frames_to_process) >= 30:
                        break
                
                frame_count += 1
            
            cap.release()
            
            # Process frames in batch
            emotions_list = analyze_frame_batch(frames_to_process, face_cascade, model)
            
            # Calculate final metrics
            result = calculate_metrics(emotions_list)
            
            return Response({
                "facialAnalysisResult": result
            }, status=status.HTTP_200_OK)
            
        finally:
            # Clean up temporary file
            if os.path.exists(temp_video_path):
                os.unlink(temp_video_path)
                
    except Exception as e:
        return Response(
            {"error": f"Processing failed: {str(e)}"}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )
